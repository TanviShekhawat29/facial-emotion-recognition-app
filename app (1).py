# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fn8_oiNjuA6kvodYw2QP1blbwdKlqDXP
"""

import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
from PIL import Image
import io

MODEL_PATH = 'facial_emotion_vgg16_7class.h5'
CASCADE_PATH = 'haarcascade_frontalface_default.xml'
IMG_SIZE = 48
EMOTIONS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

st.set_page_config(
    page_title="VGG16 Emotion Recognition",
    layout="centered",
    initial_sidebar_state="collapsed"
)

@st.cache_resource
def load_resources():
    try:
        tf.get_logger().setLevel('ERROR')

        model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        face_cascade = cv2.CascadeClassifier(CASCADE_PATH)

        if face_cascade.empty():
             st.error("Error: Face detector failed to load.")
             return None, None

        return model, face_cascade
    except Exception as e:
        st.error(f"Failed to load AI Model: {e}")
        st.warning(f"Please check if {MODEL_PATH} is present.")
        return None, None

model, face_cascade = load_resources()

def predict_emotion(image, model, face_cascade):

    img_array = np.array(image.convert('RGB'))
    gray_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(
        gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
    )

    if len(faces) == 0:
        return img_array, 0

    for (x, y, w, h) in faces:
        roi_gray = gray_img[y:y + h, x:x + w]
        cropped_img_gray = cv2.resize(roi_gray, (IMG_SIZE, IMG_SIZE))

        cropped_img_rgb = cv2.cvtColor(cropped_img_gray, cv2.COLOR_GRAY2BGR)

        processed_input = cropped_img_rgb.astype('float32') / 255.0

        processed_input = np.expand_dims(processed_input, axis=0)


        predictions = model.predict(processed_input, verbose=0)[0]

        emotion_index = np.argmax(predictions)
        emotion_label = EMOTIONS[emotion_index]
        confidence = predictions[emotion_index] * 100


        color = (255, 165, 0)

        cv2.rectangle(img_array, (x, y), (x + w, y + h), color, 2)
        text = f"{emotion_label}: {confidence:.1f}%"
        cv2.putText(img_array, text, (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

    return img_array, len(faces)


def main():
    st.title("ðŸŒŸ 7-Class Facial Emotion Recognition (VGG16)")
    st.subheader("B.Tech AI/DL Project: Transfer Learning Approach")
    st.write("---")

    if model is None:
        st.stop()

    st.info("**Strategy:** This model targets the highest possible accuracy on all 7 classes using Transfer Learning. Demo success should focus on **Happy** and **Neutral** for $85\%+$ confidence.")



if __name__ == "__main__":
    main()